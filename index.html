<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Squeezing the Last Drop of Accuracy: Hand-Eye Calibration via Deep Reinforcement Learning-Guided Pose Tuning </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon/icon.png">
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon/DALLE3_illust_icon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- <style>
    table, th, td {
        border: 1px solid black;
        border-collapse: collapse;
    }
    th, td {
        padding: 10px;
    }
  </style> -->

  <style>
    table, th, td {
      border: 1px solid black;
      border-collapse: collapse;
    }
    .item table {
      margin-left: auto; 
      margin-right: auto; 
      display: block;
      width: 90%; /* 표의 너비를 70%로 설정 */
      font-size: 16px; /* 글자 크기를 조정 */
    }
    .item th, .item td {
      padding: 10px; /* 셀의 안쪽 여백을 넓힙니다. */
    }
    .thick-border {
      border-top: 3px solid black; /* 굵은 아래 경계 설정 */
      border-collapse: collapse;
    }
    .responsive-image {
      width: 600px;  /* 원하는 너비 */
      height: 300px; /* 원하는 높이 */
      object-fit: fill; /* 이미지를 비율 유지하며 잘림 방지 */
      margin: 0 auto; /* 중앙 정렬 */
    }    
    .three-image {
      width: 900px;  /* 원하는 너비 */
      height: 450px; /* 원하는 높이 */
      object-fit: fill; /* 이미지를 비율 유지하며 잘림 방지 */
      margin: 0 auto; /* 중앙 정렬 */
    }
  </style>
  <style>
    .tool_table, .tool_table th, .tool_table td {
      border: 2px solid black; /* 테두리 색상을 파란색으로 변경하고, 두께를 2px로 조정 */
      border-collapse: collapse;
    }
    .tool_table {
      margin: 20px auto; /* 상하 마진을 20px, 좌우 마진을 자동으로 설정하여 가운데 정렬 */
      display: block;
      width: 70%; /* 표의 너비를 50%로 변경 */
      background-color: white; /* 배경색을 연회색으로 설정 */
    }
    .tool_table th, .tool_table td {
      padding: 20px; /* 셀의 안쪽 여백을 20px로 넓힙니다. */
      text-align: left; /* 텍스트를 왼쪽 정렬합니다. */
      background-color: white; /* 헤더 배경색을 파란색으로 설정 */
      color: black; /* 헤더 글자 색상을 흰색으로 설정 */
    }
  </style>

  <style>
    .license-text {
      background-color: #D3D3D3; /* 이 부분에서 회색 배경색을 지정합니다. */
      padding: 15px; /* 이 부분에서 텍스트와 테두리 사이의 여백을 지정합니다. */
    }
    .second-image {
      display: flex;
      margin: auto;
      max-width: 300px; /* 원하는 크기로 설정 */
      max-height: 450px;
      justify-content: center; /* 중앙 정렬 */
      align-items: center; /* 중앙 정렬 */
      object-fit: fill; /* 이미지를 비율 유지하며 잘림 방지 */
    }
    .map-image {
      display: flex;
      margin: auto;
      width: 300px; /* 원하는 크기로 설정 */
      height: 450px;
      justify-content: center; /* 중앙 정렬 */
      align-items: center; /* 중앙 정렬 */
      object-fit: fill; /* 이미지를 비율 유지하며 잘림 방지 */
    }
  </style>

  <style>
    .gallery {
      display: flex;
      flex-direction: column;
      gap: 20px; /* 그룹 간의 간격 */
  }
  
  .group {
      background: #f9f9f9; /* 배경색 */
      padding: 20px; /* 여백 */
      border-radius: 10px; /* 모서리 둥글게 */
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1); /* 그림자 효과 */
      overflow-y: auto; /* 세로 스크롤 추가 */
      max-height: 300px; /* 최대 높이 설정 */
  }
  
  .group h2 {
      margin-bottom: 10px; /* 제목과 이미지 간의 간격 */
  }
  
  .image-item {
      display: inline-block; /* 이미지 항목을 인라인 블록으로 설정 */
      margin: 5px; /* 이미지 간의 간격 */
  }
  
  .image-item img {
      width: 100px; /* 이미지 너비 */
      height: auto; /* 비율 유지 */
      border-radius: 5px; /* 모서리 둥글게 */
  }

  </style>
  
</head>
<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Squeezing the Last Drop of Accuracy: Hand-Eye Calibration via Deep Reinforcement Learning-Guided Pose Tuning
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Seunghui Shin</a>,</span> -->
                Seunghui Shin, Daeho Kim, Hyoseok Hwang
                <br> {jumin1116, kdh2769, hyoseok}@khu.ac.kr
                <!-- <span class="author-block"> -->
                  <!-- <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Daeho Kim</a>,</span> -->
                  
                  <!-- <span class="author-block"> -->
                    <!-- <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Hyoseok Hwang</a><sup>*</sup></span> -->

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <a href="http://airlab.khu.ac.kr/" target="_blank"> Kyung Hee University AIRLAB </a><br>IEEE Robotics and Automation Letters (RA-L) 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block"> -->
                      <!-- <a href="static/pdfs/supplementary_material.pdf" target="_blank" -->
                      <!-- class="external-link button is-normal is-rounded is-dark"> -->
                      <!-- <span class="icon"> -->
                        <!-- <i class="fas fa-file-pdf"></i> -->
                      <!-- </span> -->
                      <!-- <span>Supplementary</span> -->
                    <!-- </a> -->
                  <!-- </span> -->

                  <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/YOUR REPO HERE" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                  </a> -->
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container" style="text-align: center;">
      <video autoplay controls muted loop height="100%">
        <source src="static/video/Video.mp4" alt="Video" type="video/mp4">
      </video>
    </div>
  </div>
</section>

<style>
  .column h3 {
    font-size: 24px; /* 폰트 크기 조정 */
  }

  .column ul li {
    font-size: 18px; /* 폰트 크기 조정 */
  }

</style>
<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-fullhd"> 
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <ul>        
          <li>Hand-eye calibration is a fundamental task in robotics, requiring high precision to ensure accurate manipulation. This is especially crucial for recent markerless methods, which depend on precise pose estimation for effective end-effector calibration. In this paper, we propose a novel approach that improves calibration performance by adjusting the end-effector's pose to reduce prediction error. Our method utilizes a reward structure derived from trained pose estimation networks, enabling a Soft Actor-Critic-Discrete agent to learn in a simulated environment how to enhance calibration performance through action selection. Our experiments show that calibration results achieved with our method outperform those from initial poses alone in both markerless and marker-based methods. Real-world experiments further validate the efficacy of our approach in actual robotic systems. These results demonstrate that our proposed method effectively enhances the performance of pose estimation-based hand-eye calibration. </li>
        </ul>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper overview -->
<section class="container is-max-desktop">
  <div class="hero-body" style="text-align: center;">
    <h2 class="title">Overview</h2>

    <img src="static/images/overview.png" alt="Overview" style="max-width: 100%; height: auto; margin-bottom: 10px;">

    <h2 class="subtitle has-text-centered">
    <li>Conventional pose-based hand-eye calibration relies on the initial end-effector pose, often yielding inaccurate calibration (trajectory shown by the red arrow).</li>
    <li>Our approach leverages deep reinforcement learning (DRL) to train an agent that adjusts the end-effector toward better poses to improve calibration accuracy (trajectory shown by the blue arrow).</li>
    </h2>
  </div>
</section>

<!-- Main Architecture -->
<section class="container is-max-desktop">
  <div class="hero-body" style="text-align: center;">
    <h2 class="title">Main Architecture</h2>

    <img src="static/images/architecture.png" alt="Architecture" style="max-width: 100%; height: auto; margin-bottom: 10px;">

    <h2 class="subtitle has-text-centered">
    <li>Our framework first estimates the end-effector pose using a pose estimation network.</li>
    <li>Subsequently, a SAC-Discrete agent is trained to adjust the end-effector to poses that yield lower estimation errors.</li>
    <li>Hand-eye calibration is then performed using the known forward kinematics and the refined end-effector poses.</li>

    </h2>
  </div>
</section>
  
<!-- Evaluation -->
<section class="container is-max-desktop">
  <div class="hero-body" style="text-align: center;">
    <h2 class="title">Evaluation in Simulation</h2>

    <!-- Markerless subsection -->
    <h3 class="subtitle has-text-centered" style="margin-top: 20px; font-weight: bold;">
      Markerless Calibration
    </h3>
    <img src="static/images/markerless.png" 
         alt="Markerless Calibration Results" 
         style="max-width: 100%; height: auto; margin-bottom: 10px;">
    <p class="has-text-centered" style="max-width: 800px; margin: 0 auto;">
      Our method significantly reduced estimation errors for hand-eye calibration. 
      Trends in end-effector pose estimation matched those in calibration, 
      as expected, since calibration depended directly on pose accuracy. 
      These results confirmed that our approach effectively guided the end-effector toward poses that reduced errors, 
      enhancing both pose estimation and calibration performance. 
      Moreover, our method was modular and could be integrated into various pose estimation networks.
    </p>

    <!-- Marker-Based subsection -->
    <h3 class="subtitle has-text-centered" style="margin-top: 40px; font-weight: bold;">
      Marker-Based Calibration
    </h3>
    <img src="static/images/markerbased.png" 
         alt="Marker-Based Calibration Results" 
         style="max-width: 100%; height: auto; margin-bottom: 10px;">
    <p class="has-text-centered" style="max-width: 800px; margin: 0 auto;">
      The calibration performance was highly sensitive to marker pose accuracy; increased marker pose error led to larger calibration errors.
      By guiding the end-effector to poses with lower estimation errors, our method effectively reduced errors in both marker pose estimation and hand-eye calibration, demonstrating its utility in improving marker-based settings.
    </p>
  </div>
</section>

<!-- Evaluation in Real-World Setting -->
<section class="container is-max-desktop">
  <div class="hero-body" style="text-align: center;">
    <h2 class="title">Evaluation in Real-World Setting</h2>

    <!-- First experiment -->
    <h3 class="subtitle has-text-centered" style="margin-top: 20px; font-weight: bold;">
      High-Precision Targeting
    </h3>
    <figure class="image">
      <img src="static/images/realworld1.png" 
           alt="Real-world Experiment 1" 
           style="max-width: 600px; width: 90%; border-radius: 8px; display: block; margin-bottom: 10px;">
    </figure>
    <p class="has-text-centered" style="max-width: 700px; margin: 0 auto;">
      Our method consistently reduced calibration errors, while the random policy gave marginal improvement or increased error.
      These results confirmed the effectiveness of our approach in improving real-world hand-eye calibration.
    </p>

    <!-- Second experiment -->
    <h3 class="subtitle has-text-centered" style="margin-top: 40px; font-weight: bold;">
      Peg-Insertion
    </h3>
    <figure class="image">
      <img src="static/images/realworld2.png" 
           alt="Real-world Experiment 2" 
           style="max-width: 600px; width: 90%; border-radius: 8px; display: block; margin-bottom: 10px;">
    </figure>
    <p class="has-text-centered" style="max-width: 700px; margin: 0 auto;">
      Integrating our method increased task success 71%, showing even small improvements in hand-eye calibration substantially enhance real-world task execution.
    </p>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{,
                  title={},
                  author={},
                  journal={},
                  year={},
                  publisher={}
                }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
